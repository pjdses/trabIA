{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90355aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.23.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: packaging in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.56.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.13)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.10.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.21.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\mayko\\anaconda 3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ddb6e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: conda-script.py [-h] [-V] command ...\n",
      "conda-script.py: error: unrecognized arguments: keras-rectified-adam\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge keras-rectified-adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3db3142e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_radam'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m binary_crossentropy\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_model\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras_radam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RAdam\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n\u001b[0;32m     21\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_radam'"
     ]
    }
   ],
   "source": [
    "import logging, os\n",
    "import random\n",
    "import tqdm\n",
    "import keras\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from keras.layers import Dense, Input, concatenate\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras_radam import RAdam\n",
    "from keras import backend as K\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b05da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Configurar a semente (seed) para a geração de números pseudoaleatórios\n",
    "seed_value = 0\n",
    "\n",
    "#Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "#Set `python` built-in pseudo-random generator at a fixed value\n",
    "random.seed(seed_value)\n",
    "\n",
    "#Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "#Set `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "#Configure a new global `tensorflow` session\n",
    "session_conf = tf.compat.v1.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9aa8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as características categóricas e seus mapeamentos\n",
    "str_att = {\n",
    "  'length': ['short', 'long'],\n",
    "  'shape': ['closedrect', 'dblopnrect', 'ellipse', 'engine', 'hexagon',\n",
    "          'jaggedtop', 'openrect', 'opentrap', 'slopetop', 'ushaped'],\n",
    "  'load_shape': ['circlelod', 'hexagonlod', 'rectanglod', 'trianglod'],\n",
    "  'Class_attribute': ['west','east']\n",
    "}\n",
    "\n",
    "# Ler os dados do arquivo CSV\n",
    "data = pd.read_csv('dados-trens.csv')\n",
    "\n",
    "# Transformar os valores categóricos em numéricos\n",
    "data['Class_attribute'] = data['Class_attribute'].map({'east': 1, 'west': -1})\n",
    "\n",
    "# Aplicar os mapeamentos para características categóricas\n",
    "for k in data:\n",
    "    for att in str_att:\n",
    "        if k.startswith(att):\n",
    "            for i, val in enumerate(data[k]):\n",
    "                if val in str_att[att]:\n",
    "                    data.at[i, k] = str_att[att].index(val)\n",
    "\n",
    "# Substituir valores específicos por outros\n",
    "data.replace(\"\\\\0\", 0, inplace=True)\n",
    "data.replace(\"None\", -1, inplace=True)\n",
    "\n",
    "\n",
    "data = data.fillna(-1)\n",
    "\n",
    "# Para primeiro teste, recebe um indo para o oeste e dois para o leste e remove dos casos de treinamento.\n",
    "array_test = []\n",
    "test_data = random.randint(6,9)\n",
    "x = random.randint(0, 4)\n",
    "y = random.randint(0, 4)\n",
    "while (x == y):\n",
    "    y = random.randint(0,4)\n",
    "array_test.append([test_data, x, y])\n",
    "array_test = array_test[0]\n",
    "\n",
    "first_training_data = data.drop(array_test)\n",
    "first_test_data = data.iloc[array_test]\n",
    "\n",
    "# Separar as características (entradas) e o rótulo (saída) da classe\n",
    "X = first_training_data.drop('Class_attribute', axis=1)\n",
    "y = first_training_data['Class_attribute']\n",
    "X_test = first_test_data.drop('Class_attribute', axis=1)\n",
    "y_test = first_test_data['Class_attribute']\n",
    "\n",
    "\n",
    "array_test = []\n",
    "test_data = random.randint(0, 4)\n",
    "x = random.randint(5, 9)\n",
    "y1 = random.randint(5, 9)\n",
    "while (x == y1):\n",
    "    y1 = random.randint(5, 9)\n",
    "array_test.append([test_data, x, y1])\n",
    "array_test = array_test[0]\n",
    "\n",
    "scnd_training_data = data.drop(array_test)\n",
    "scnd_test_data = data.iloc[array_test]\n",
    "\n",
    "# Separar as características (entradas) e o rótulo (saída) da classe\n",
    "X2 = scnd_training_data.drop('Class_attribute', axis=1)\n",
    "y2 = scnd_training_data['Class_attribute']\n",
    "X_test2 = scnd_test_data.drop('Class_attribute', axis=1)\n",
    "y_test2 = scnd_test_data['Class_attribute']\n",
    "\n",
    "# Função para criar a rede neural\n",
    "def create_neural_network():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=10, activation='linear', input_shape=(X.shape[1],)))\n",
    "    model.add(Dense(units=1, activation='tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a280e0d",
   "metadata": {},
   "source": [
    "# Questão 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#teste 1: \n",
    "\n",
    "model = create_neural_network()\n",
    "\n",
    "X_train_tensor = tf.convert_to_tensor(X.values, dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y.values, dtype=tf.float32)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test.values, dtype=tf.float32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test.values, dtype=tf.float32)\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Treinar a rede neural\n",
    "model.fit(X_train_tensor, y_train_tensor, epochs=20, verbose=0)\n",
    "predictions = model.predict(X_test_tensor)\n",
    "\n",
    "predictions[predictions >= 0] = 1.0\n",
    "predictions[predictions < 0] = -1.0\n",
    "\n",
    "print(y_test_tensor)\n",
    "\n",
    "counter = 0\n",
    "for i in range(0, 3):\n",
    "    print(predictions[i][0], \" -> \", y_test_tensor.numpy().tolist()[i])\n",
    "    if predictions[i][0] == y_test_tensor.numpy().tolist()[i]:\n",
    "        counter += 1\n",
    "\n",
    "print(\"Acurácia: \", (counter * 100 / 3), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59754c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#teste2\n",
    "\n",
    "model = create_neural_network()\n",
    "\n",
    "X_train_tensor = tf.convert_to_tensor(X2.values, dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y2.values, dtype=tf.float32)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test2.values, dtype=tf.float32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test2.values, dtype=tf.float32)\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Treinar a rede neural\n",
    "model.fit(X_train_tensor, y_train_tensor, epochs=20, verbose=0)\n",
    "predictions = model.predict(X_test_tensor)\n",
    "\n",
    "predictions[predictions >= 0] = 1.0\n",
    "predictions[predictions < 0] = -1.0\n",
    "\n",
    "counter = 0\n",
    "for i in range(0, 3):\n",
    "    print(predictions[i][0], \" -> \", y_test_tensor.numpy().tolist()[i])\n",
    "    if predictions[i][0] == y_test_tensor.numpy().tolist()[i]:\n",
    "        counter += 1\n",
    "\n",
    "print(\"Acurácia: \", (counter * 100 / 3), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965736a",
   "metadata": {},
   "source": [
    "# Questão 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d7c303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the data\n",
    "path = \"dados-trens.csv\"\n",
    "\n",
    "\n",
    "def read_data(path=path):\n",
    "    df = pd.read_csv(path, \",\")\n",
    "\n",
    "    for k in df:\n",
    "        for att in str_att:\n",
    "            if k.startswith(att):\n",
    "                for i, val in enumerate(df[k]):\n",
    "                    if val in str_att[att]:\n",
    "                        df[k][i] = str_att[att].index(val)\n",
    "\n",
    "    df.replace(\"\\\\0\", 0, inplace=True)\n",
    "    df.replace(\"None\", -1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e919d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2():\n",
    "    # features\n",
    "    t = Input(shape=(1,), name=\"t\")\n",
    "    c = Input(shape=(1,), name=\"c\")\n",
    "    w = Input(shape=(1,), name=\"w\")\n",
    "    l = Input(shape=(1,), name=\"l\")\n",
    "    s = Input(shape=(1,), name=\"s\")\n",
    "    nc = Input(shape=(1,), name=\"nc\")\n",
    "    ls = Input(shape=(1,), name=\"ls\")\n",
    "    nl = Input(shape=(1,), name=\"nl\")\n",
    "    ncl = Input(shape=(1,), name=\"ncl\")\n",
    "    x_crc = Input(shape=(1,), name=\"x_crc\")\n",
    "    x_hex = Input(shape=(1,), name=\"x_hex\")\n",
    "    x_rec = Input(shape=(1,), name=\"x_rec\")\n",
    "    x_tri = Input(shape=(1,), name=\"x_tri\")\n",
    "\n",
    "    # num_cars(t,nc)\n",
    "    num_cars_ = concatenate([t, nc])\n",
    "    num_cars_ = Dense(20, activation=\"relu\")(num_cars_)\n",
    "    num_cars = Dense(1, activation=\"sigmoid\", name=\"num_cars\")(num_cars_)\n",
    "    num_cars = Model(inputs=[t, nc], outputs=num_cars)\n",
    "\n",
    "    # num_loads(t,nl)\n",
    "    num_loads_ = concatenate([t, nl])\n",
    "    num_loads_ = Dense(20, activation=\"relu\")(num_loads_)\n",
    "    num_loads = Dense(1, activation=\"sigmoid\", name=\"num_loads\")(num_loads_)\n",
    "    num_loads = Model(inputs=[t, nl], outputs=num_loads)\n",
    "\n",
    "    # num_wheels(t,c,w)\n",
    "    num_wheels_ = concatenate([t, c, w])\n",
    "    num_wheels_ = Dense(20, activation=\"relu\")(num_wheels_)\n",
    "    num_wheels = Dense(1, activation=\"sigmoid\", name=\"num_wheels\")(num_wheels_)\n",
    "    num_wheels = Model(inputs=[t, c, w], outputs=num_wheels)\n",
    "\n",
    "    # length(t,c,l)\n",
    "    length_ = concatenate([t, c, l])\n",
    "    length_ = Dense(20, activation=\"relu\")(length_)\n",
    "    length = Dense(1, activation=\"sigmoid\", name=\"length\")(length_)\n",
    "    length = Model(inputs=[t, c, l], outputs=length)\n",
    "\n",
    "    # shape(t,c,s)\n",
    "    shape_ = concatenate([t, c, s])\n",
    "    shape_ = Dense(20, activation=\"relu\")(shape_)\n",
    "    shape = Dense(1, activation=\"sigmoid\", name=\"shape\")(shape_)\n",
    "    shape = Model(inputs=[t, c, s], outputs=shape)\n",
    "\n",
    "    # num_car_loads(t,c,ncl)\n",
    "    num_car_loads_ = concatenate([t, c, ncl])\n",
    "    num_car_loads_ = Dense(20, activation=\"relu\")(num_car_loads_)\n",
    "    num_car_loads = Dense(1, activation=\"sigmoid\", name=\"num_car_loads\")(num_car_loads_)\n",
    "    num_car_loads = Model(inputs=[t, c, ncl], outputs=num_car_loads)\n",
    "\n",
    "    # load_shape(t,c,ls)\n",
    "    load_shape_ = concatenate([t, c, ls])\n",
    "    load_shape_ = Dense(20, activation=\"relu\")(load_shape_)\n",
    "    load_shape = Dense(1, activation=\"sigmoid\", name=\"load_shape\")(load_shape_)\n",
    "    load_shape = Model(inputs=[t, c, ls], outputs=load_shape)\n",
    "\n",
    "    # next_crc(t,c,x)\n",
    "    next_crc_ = concatenate([t, c, x_crc])\n",
    "    next_crc_ = Dense(20, activation=\"relu\")(next_crc_)\n",
    "    next_crc = Dense(1, activation=\"sigmoid\", name=\"next_crc\")(next_crc_)\n",
    "    next_crc = Model(inputs=[t, c, x_crc], outputs=next_crc)\n",
    "\n",
    "    # next_hex_(t,c,x)\n",
    "    next_hex_ = concatenate([t, c, x_hex])\n",
    "    next_hex_ = Dense(20, activation=\"relu\")(next_hex_)\n",
    "    next_hex = Dense(1, activation=\"sigmoid\", name=\"next_hex\")(next_hex_)\n",
    "    next_hex = Model(inputs=[t, c, x_hex], outputs=next_hex)\n",
    "\n",
    "    # next_rec(t,c,x)\n",
    "    next_rec_ = concatenate([t, c, x_rec])\n",
    "    next_rec_ = Dense(20, activation=\"relu\")(next_rec_)\n",
    "    next_rec = Dense(1, activation=\"sigmoid\", name=\"next_rec\")(next_rec_)\n",
    "    next_rec = Model(inputs=[t, c, x_rec], outputs=next_rec)\n",
    "\n",
    "    # next_tri(t,c,x)\n",
    "    next_tri_ = concatenate([t, c, x_tri])\n",
    "    next_tri_ = Dense(20, activation=\"relu\")(next_tri_)\n",
    "    next_tri = Dense(1, activation=\"sigmoid\", name=\"next_tri\")(next_tri_)\n",
    "    next_tri = Model(inputs=[t, c, x_tri], outputs=next_tri)\n",
    "\n",
    "    # east\n",
    "    east = concatenate(\n",
    "        [\n",
    "            num_cars_,\n",
    "            num_loads_,\n",
    "            num_wheels_,\n",
    "            length_,\n",
    "            shape_,\n",
    "            num_car_loads_,\n",
    "            load_shape_,\n",
    "            next_crc_,\n",
    "            next_hex_,\n",
    "            next_rec_,\n",
    "            next_tri_,\n",
    "        ]\n",
    "    )\n",
    "    east = Dense(3, activation=\"relu\")(east)\n",
    "    east = Dense(1, activation=\"sigmoid\", name=\"east\")(east)\n",
    "    east = Model(\n",
    "        inputs=[t, c, w, l, s, nc, ls, nl, ncl, x_crc, x_hex, x_rec, x_tri],\n",
    "        outputs=east,\n",
    "    )\n",
    "\n",
    "    # metanet\n",
    "    metanet = Model(\n",
    "        inputs=east.inputs,\n",
    "        outputs=[\n",
    "            num_cars.output,\n",
    "            num_loads.output,\n",
    "            num_wheels.output,\n",
    "            length.output,\n",
    "            shape.output,\n",
    "            num_car_loads.output,\n",
    "            load_shape.output,\n",
    "            next_crc.output,\n",
    "            next_hex.output,\n",
    "            next_rec.output,\n",
    "            next_tri.output,\n",
    "            east.output,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # rules\n",
    "    rules = {\n",
    "        \"num_cars\": num_cars,\n",
    "        \"num_loads\": num_loads,\n",
    "        \"num_wheels\": num_wheels,\n",
    "        \"length\": length,\n",
    "        \"shape\": shape,\n",
    "        \"num_car_loads\": num_car_loads,\n",
    "        \"load_shape\": load_shape,\n",
    "        \"next_crc\": next_crc,\n",
    "        \"next_hex\": next_hex,\n",
    "        \"next_rec\": next_rec,\n",
    "        \"next_tri\": next_tri,\n",
    "    }\n",
    "    \n",
    "    # Camada de meta-aprendizado\n",
    "    meta_input = concatenate([\n",
    "        num_cars.output,\n",
    "        num_loads.output,\n",
    "        num_wheels.output,\n",
    "        length.output,\n",
    "        shape.output,\n",
    "        num_car_loads.output,\n",
    "        load_shape.output,\n",
    "        next_crc.output,\n",
    "        next_hex.output,\n",
    "        next_rec.output,\n",
    "        next_tri.output,\n",
    "        east.output\n",
    "    ])\n",
    "    meta_hidden = Dense(20, activation=\"relu\")(meta_input)\n",
    "    meta_output = Dense(1, activation=\"sigmoid\", name=\"meta_output\")(meta_hidden)\n",
    "    meta_net = Model(inputs=metanet.inputs, outputs=meta_output)\n",
    "\n",
    "    # Adicionar meta-aprendizado à saída do modelo leste (east)\n",
    "    east_output = east.outputs\n",
    "    east_output.append(meta_output)\n",
    "    east = Model(inputs=east.inputs, outputs=east_output)\n",
    "\n",
    "    return metanet, east, rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc1ef752",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Compilação do modelo\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m metanet, east, rules \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m east\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Treinamento do modelo\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m, in \u001b[0;36mmodel_2\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_2\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# features\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mInput\u001b[49m(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     c \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     w \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "# Divisão dos dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Compilação do modelo\n",
    "metanet, east, rules = model_2()\n",
    "east.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Treinamento do modelo\n",
    "east.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Avaliação do modelo\n",
    "loss, accuracy = east.evaluate(X_test, y_test)\n",
    "print(\"Acurácia:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
