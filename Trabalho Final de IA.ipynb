{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90355aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdb0821",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras-rectified-adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db3142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging, os\n",
    "import random\n",
    "import tqdm\n",
    "import keras\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from keras.layers import Dense, Input, concatenate\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras_radam import RAdam\n",
    "from keras import backend as K\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b05da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Configurar a semente (seed) para a geração de números pseudoaleatórios\n",
    "seed_value = 0\n",
    "\n",
    "#Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "\n",
    "#Set `python` built-in pseudo-random generator at a fixed value\n",
    "random.seed(seed_value)\n",
    "\n",
    "#Set `numpy` pseudo-random generator at a fixed value\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "#Set `tensorflow` pseudo-random generator at a fixed value\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "#Configure a new global `tensorflow` session\n",
    "session_conf = tf.compat.v1.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9aa8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as características categóricas e seus mapeamentos\n",
    "str_att = {\n",
    "  'length': ['short', 'long'],\n",
    "  'shape': ['closedrect', 'dblopnrect', 'ellipse', 'engine', 'hexagon',\n",
    "          'jaggedtop', 'openrect', 'opentrap', 'slopetop', 'ushaped'],\n",
    "  'load_shape': ['circlelod', 'hexagonlod', 'rectanglod', 'trianglod'],\n",
    "  'Class_attribute': ['west','east']\n",
    "}\n",
    "\n",
    "# Ler os dados do arquivo CSV\n",
    "data = pd.read_csv('dados-trens.csv')\n",
    "\n",
    "# Transformar os valores categóricos em numéricos\n",
    "data['Class_attribute'] = data['Class_attribute'].map({'east': 1, 'west': -1})\n",
    "\n",
    "# Aplicar os mapeamentos para características categóricas\n",
    "for k in data:\n",
    "    for att in str_att:\n",
    "        if k.startswith(att):\n",
    "            for i, val in enumerate(data[k]):\n",
    "                if val in str_att[att]:\n",
    "                    data.at[i, k] = str_att[att].index(val)\n",
    "\n",
    "# Substituir valores específicos por outros\n",
    "data.replace(\"\\\\0\", 0, inplace=True)\n",
    "data.replace(\"None\", -1, inplace=True)\n",
    "\n",
    "\n",
    "data = data.fillna(-1)\n",
    "\n",
    "# Para primeiro teste, recebe um indo para o oeste e dois para o leste e remove dos casos de treinamento.\n",
    "array_test = []\n",
    "test_data = random.randint(6,9)\n",
    "x = random.randint(0, 4)\n",
    "y = random.randint(0, 4)\n",
    "while (x == y):\n",
    "    y = random.randint(0,4)\n",
    "array_test.append([test_data, x, y])\n",
    "array_test = array_test[0]\n",
    "\n",
    "first_training_data = data.drop(array_test)\n",
    "first_test_data = data.iloc[array_test]\n",
    "\n",
    "# Separar as características (entradas) e o rótulo (saída) da classe\n",
    "X = first_training_data.drop('Class_attribute', axis=1)\n",
    "y = first_training_data['Class_attribute']\n",
    "X_test = first_test_data.drop('Class_attribute', axis=1)\n",
    "y_test = first_test_data['Class_attribute']\n",
    "\n",
    "\n",
    "array_test = []\n",
    "test_data = random.randint(0, 4)\n",
    "x = random.randint(5, 9)\n",
    "y1 = random.randint(5, 9)\n",
    "while (x == y1):\n",
    "    y1 = random.randint(5, 9)\n",
    "array_test.append([test_data, x, y1])\n",
    "array_test = array_test[0]\n",
    "\n",
    "scnd_training_data = data.drop(array_test)\n",
    "scnd_test_data = data.iloc[array_test]\n",
    "\n",
    "# Separar as características (entradas) e o rótulo (saída) da classe\n",
    "X2 = scnd_training_data.drop('Class_attribute', axis=1)\n",
    "y2 = scnd_training_data['Class_attribute']\n",
    "X_test2 = scnd_test_data.drop('Class_attribute', axis=1)\n",
    "y_test2 = scnd_test_data['Class_attribute']\n",
    "\n",
    "# Função para criar a rede neural\n",
    "def create_neural_network():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=10, activation='linear', input_shape=(X.shape[1],)))\n",
    "    model.add(Dense(units=1, activation='tanh'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2612347f",
   "metadata": {},
   "source": [
    "# Questão 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b8982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#teste 1: \n",
    "\n",
    "model = create_neural_network()\n",
    "\n",
    "X_train_tensor = tf.convert_to_tensor(X.values, dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y.values, dtype=tf.float32)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test.values, dtype=tf.float32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test.values, dtype=tf.float32)\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Treinar a rede neural\n",
    "model.fit(X_train_tensor, y_train_tensor, epochs=20, verbose=0)\n",
    "predictions = model.predict(X_test_tensor)\n",
    "\n",
    "predictions[predictions >= 0] = 1.0\n",
    "predictions[predictions < 0] = -1.0\n",
    "\n",
    "print(y_test_tensor)\n",
    "\n",
    "counter = 0\n",
    "for i in range(0, 3):\n",
    "    print(predictions[i][0], \" -> \", y_test_tensor.numpy().tolist()[i])\n",
    "    if predictions[i][0] == y_test_tensor.numpy().tolist()[i]:\n",
    "        counter += 1\n",
    "\n",
    "print(\"Acurácia: \", (counter * 100 / 3), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59754c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#teste2\n",
    "\n",
    "model = create_neural_network()\n",
    "\n",
    "X_train_tensor = tf.convert_to_tensor(X2.values, dtype=tf.float32)\n",
    "y_train_tensor = tf.convert_to_tensor(y2.values, dtype=tf.float32)\n",
    "X_test_tensor = tf.convert_to_tensor(X_test2.values, dtype=tf.float32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test2.values, dtype=tf.float32)\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Treinar a rede neural\n",
    "model.fit(X_train_tensor, y_train_tensor, epochs=20, verbose=0)\n",
    "predictions = model.predict(X_test_tensor)\n",
    "\n",
    "predictions[predictions >= 0] = 1.0\n",
    "predictions[predictions < 0] = -1.0\n",
    "\n",
    "counter = 0\n",
    "for i in range(0, 3):\n",
    "    print(predictions[i][0], \" -> \", y_test_tensor.numpy().tolist()[i])\n",
    "    if predictions[i][0] == y_test_tensor.numpy().tolist()[i]:\n",
    "        counter += 1\n",
    "\n",
    "print(\"Acurácia: \", (counter * 100 / 3), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6176dc",
   "metadata": {},
   "source": [
    "# Questão 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the data\n",
    "path = \"dados-trens.csv\"\n",
    "\n",
    "def read_data(path=path):\n",
    "    df = pd.read_csv(path, \",\")\n",
    "\n",
    "    for k in df:\n",
    "        for att in str_att:\n",
    "            if k.startswith(att):\n",
    "                for i, val in enumerate(df[k]):\n",
    "                    if val in str_att[att]:\n",
    "                        df[k][i] = str_att[att].index(val)\n",
    "\n",
    "    df.replace(\"\\\\0\", 0, inplace=True)\n",
    "    df.replace(\"None\", -1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb41dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2():\n",
    "    # features\n",
    "    t = Input(shape=(1,), name=\"t\")\n",
    "    c = Input(shape=(1,), name=\"c\")\n",
    "    w = Input(shape=(1,), name=\"w\")\n",
    "    l = Input(shape=(1,), name=\"l\")\n",
    "    s = Input(shape=(1,), name=\"s\")\n",
    "    nc = Input(shape=(1,), name=\"nc\")\n",
    "    ls = Input(shape=(1,), name=\"ls\")\n",
    "    nl = Input(shape=(1,), name=\"nl\")\n",
    "    ncl = Input(shape=(1,), name=\"ncl\")\n",
    "    x_crc = Input(shape=(1,), name=\"x_crc\")\n",
    "    x_hex = Input(shape=(1,), name=\"x_hex\")\n",
    "    x_rec = Input(shape=(1,), name=\"x_rec\")\n",
    "    x_tri = Input(shape=(1,), name=\"x_tri\")\n",
    "\n",
    "    # num_cars(t,nc)\n",
    "    num_cars_ = concatenate([t, nc])\n",
    "    num_cars_ = Dense(20, activation=\"relu\")(num_cars_)\n",
    "    num_cars = Dense(1, activation=\"sigmoid\", name=\"num_cars\")(num_cars_)\n",
    "    num_cars = Model(inputs=[t, nc], outputs=num_cars)\n",
    "\n",
    "    # num_loads(t,nl)\n",
    "    num_loads_ = concatenate([t, nl])\n",
    "    num_loads_ = Dense(20, activation=\"relu\")(num_loads_)\n",
    "    num_loads = Dense(1, activation=\"sigmoid\", name=\"num_loads\")(num_loads_)\n",
    "    num_loads = Model(inputs=[t, nl], outputs=num_loads)\n",
    "\n",
    "    # num_wheels(t,c,w)\n",
    "    num_wheels_ = concatenate([t, c, w])\n",
    "    num_wheels_ = Dense(20, activation=\"relu\")(num_wheels_)\n",
    "    num_wheels = Dense(1, activation=\"sigmoid\", name=\"num_wheels\")(num_wheels_)\n",
    "    num_wheels = Model(inputs=[t, c, w], outputs=num_wheels)\n",
    "\n",
    "    # length(t,c,l)\n",
    "    length_ = concatenate([t, c, l])\n",
    "    length_ = Dense(20, activation=\"relu\")(length_)\n",
    "    length = Dense(1, activation=\"sigmoid\", name=\"length\")(length_)\n",
    "    length = Model(inputs=[t, c, l], outputs=length)\n",
    "\n",
    "    # shape(t,c,s)\n",
    "    shape_ = concatenate([t, c, s])\n",
    "    shape_ = Dense(20, activation=\"relu\")(shape_)\n",
    "    shape = Dense(1, activation=\"sigmoid\", name=\"shape\")(shape_)\n",
    "    shape = Model(inputs=[t, c, s], outputs=shape)\n",
    "\n",
    "    # num_car_loads(t,c,ncl)\n",
    "    num_car_loads_ = concatenate([t, c, ncl])\n",
    "    num_car_loads_ = Dense(20, activation=\"relu\")(num_car_loads_)\n",
    "    num_car_loads = Dense(1, activation=\"sigmoid\", name=\"num_car_loads\")(num_car_loads_)\n",
    "    num_car_loads = Model(inputs=[t, c, ncl], outputs=num_car_loads)\n",
    "\n",
    "    # load_shape(t,c,ls)\n",
    "    load_shape_ = concatenate([t, c, ls])\n",
    "    load_shape_ = Dense(20, activation=\"relu\")(load_shape_)\n",
    "    load_shape = Dense(1, activation=\"sigmoid\", name=\"load_shape\")(load_shape_)\n",
    "    load_shape = Model(inputs=[t, c, ls], outputs=load_shape)\n",
    "\n",
    "    # next_crc(t,c,x)\n",
    "    next_crc_ = concatenate([t, c, x_crc])\n",
    "    next_crc_ = Dense(20, activation=\"relu\")(next_crc_)\n",
    "    next_crc = Dense(1, activation=\"sigmoid\", name=\"next_crc\")(next_crc_)\n",
    "    next_crc = Model(inputs=[t, c, x_crc], outputs=next_crc)\n",
    "\n",
    "    # next_hex_(t,c,x)\n",
    "    next_hex_ = concatenate([t, c, x_hex])\n",
    "    next_hex_ = Dense(20, activation=\"relu\")(next_hex_)\n",
    "    next_hex = Dense(1, activation=\"sigmoid\", name=\"next_hex\")(next_hex_)\n",
    "    next_hex = Model(inputs=[t, c, x_hex], outputs=next_hex)\n",
    "\n",
    "    # next_rec(t,c,x)\n",
    "    next_rec_ = concatenate([t, c, x_rec])\n",
    "    next_rec_ = Dense(20, activation=\"relu\")(next_rec_)\n",
    "    next_rec = Dense(1, activation=\"sigmoid\", name=\"next_rec\")(next_rec_)\n",
    "    next_rec = Model(inputs=[t, c, x_rec], outputs=next_rec)\n",
    "\n",
    "    # next_tri(t,c,x)\n",
    "    next_tri_ = concatenate([t, c, x_tri])\n",
    "    next_tri_ = Dense(20, activation=\"relu\")(next_tri_)\n",
    "    next_tri = Dense(1, activation=\"sigmoid\", name=\"next_tri\")(next_tri_)\n",
    "    next_tri = Model(inputs=[t, c, x_tri], outputs=next_tri)\n",
    "\n",
    "    # east\n",
    "    east = concatenate(\n",
    "        [\n",
    "            num_cars_,\n",
    "            num_loads_,\n",
    "            num_wheels_,\n",
    "            length_,\n",
    "            shape_,\n",
    "            num_car_loads_,\n",
    "            load_shape_,\n",
    "            next_crc_,\n",
    "            next_hex_,\n",
    "            next_rec_,\n",
    "            next_tri_,\n",
    "        ]\n",
    "    )\n",
    "    east = Dense(3, activation=\"relu\")(east)\n",
    "    east = Dense(1, activation=\"sigmoid\", name=\"east\")(east)\n",
    "    east = Model(\n",
    "        inputs=[t, c, w, l, s, nc, ls, nl, ncl, x_crc, x_hex, x_rec, x_tri],\n",
    "        outputs=east,\n",
    "    )\n",
    "\n",
    "    # metanet\n",
    "    metanet = Model(\n",
    "        inputs=east.inputs,\n",
    "        outputs=[\n",
    "            num_cars.output,\n",
    "            num_loads.output,\n",
    "            num_wheels.output,\n",
    "            length.output,\n",
    "            shape.output,\n",
    "            num_car_loads.output,\n",
    "            load_shape.output,\n",
    "            next_crc.output,\n",
    "            next_hex.output,\n",
    "            next_rec.output,\n",
    "            next_tri.output,\n",
    "            east.output,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # rules\n",
    "    rules = {\n",
    "        \"num_cars\": num_cars,\n",
    "        \"num_loads\": num_loads,\n",
    "        \"num_wheels\": num_wheels,\n",
    "        \"length\": length,\n",
    "        \"shape\": shape,\n",
    "        \"num_car_loads\": num_car_loads,\n",
    "        \"load_shape\": load_shape,\n",
    "        \"next_crc\": next_crc,\n",
    "        \"next_hex\": next_hex,\n",
    "        \"next_rec\": next_rec,\n",
    "        \"next_tri\": next_tri,\n",
    "    }\n",
    "    \n",
    "    # Camada de meta-aprendizado\n",
    "    meta_input = concatenate([\n",
    "        num_cars.output,\n",
    "        num_loads.output,\n",
    "        num_wheels.output,\n",
    "        length.output,\n",
    "        shape.output,\n",
    "        num_car_loads.output,\n",
    "        load_shape.output,\n",
    "        next_crc.output,\n",
    "        next_hex.output,\n",
    "        next_rec.output,\n",
    "        next_tri.output,\n",
    "        east.output\n",
    "    ])\n",
    "    meta_hidden = Dense(20, activation=\"relu\")(meta_input)\n",
    "    meta_output = Dense(1, activation=\"sigmoid\", name=\"meta_output\")(meta_hidden)\n",
    "    meta_net = Model(inputs=metanet.inputs, outputs=meta_output)\n",
    "\n",
    "    # Adicionar meta-aprendizado à saída do modelo leste (east)\n",
    "    east_output = east.outputs\n",
    "    east_output.append(meta_output)\n",
    "    east = Model(inputs=east.inputs, outputs=east_output)\n",
    "\n",
    "    return metanet, east, rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c9fce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Compilação do modelo\n",
    "metanet, east, rules = model_2()\n",
    "east.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Treinamento do modelo\n",
    "east.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Avaliação do modelo\n",
    "loss, accuracy = east.evaluate(X_test, y_test)\n",
    "print(\"Acurácia:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
